{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# !{sys.executable} -m pip install xgboost\n",
    "import xgboost as xgb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !{sys.executable} -m pip install Sentence-transformer\n",
    "from sentence_transformers import SentenceTransformer,util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys  \n",
    "sys.path.insert(1, '/home/jovyan/work/core') \n",
    "import core_utils "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read labelled dataset \n",
    "df_labels = pd.read_csv('../inputs/bert_3k_true_labels.csv',index_col=None)\n",
    "df_labels.drop_duplicates(subset=['keys'],keep='first',inplace=True)\n",
    "true_labels = dict(zip(df_labels['keys'],df_labels['real']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f7bfeded610>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Figure 5\n",
    "df_f6 = pd.read_csv('../outputs/formats_evaluation_f1.csv',index_col='model')\n",
    "df_f6.plot(kind='bar',rot=0,ylim=(0.5,1),colormap='coolwarm',xlabel='').legend(bbox_to_anchor=(1,1.01),loc='upper right',fontsize=12)\n",
    "# the full table is in outputs/format_evaluation_precision.csv\n",
    "# To reproduce this file run the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "################ Experiment_1  ################\n",
    "\n",
    "# First we download the pre trained model\n",
    "# This line takes some time\n",
    "sbert = SentenceTransformer('all-mpnet-base-v2')\n",
    "\n",
    "# to save the model locally, run the following command\n",
    "# sbert.save(path='../embeddings/sent_bert/',model_name='all-mpnet-base-v2')\n",
    "\n",
    "header = ['input','learning','accuracy','precision','recall','f1']\n",
    "output = []\n",
    "\n",
    "# Name for the input dataset. Formats are ready for the embedding layer\n",
    "inputs = ['bert_3k_formatA.csv','bert_3k_formatB.csv','bert_3k_formatC.csv','bert_3k_formatD.csv']\n",
    "base = '../inputs/'\n",
    "\n",
    "classifiers = []\n",
    "\n",
    "for input in inputs:\n",
    "    # read input documentation\n",
    "    format = input.replace('bert_3k_','').replace('.csv','')\n",
    "    df = pd.read_csv(base + input,index_col=None)\n",
    "    df.drop_duplicates(keep='first',inplace=True)\n",
    "    df['real'] = [true_labels[x] for x in df['keys']]\n",
    "    \n",
    "    # embed the method documentation\n",
    "    X_original = sbert.encode(df['docs'].values)\n",
    "\n",
    "    label_encoder = LabelEncoder()\n",
    "    label_encoder = label_encoder.fit(df['real'].values)\n",
    "    label_encoded_y = label_encoder.transform(df['real'].values)\n",
    "    \n",
    "    x_train, x_test, y_train, y_test = train_test_split(X_original,\n",
    "                                     label_encoded_y, test_size=0.25, random_state=0) #\n",
    "\n",
    "    \n",
    "    # Run classifiers\n",
    "    \n",
    "    learning = 'logistic'\n",
    "    logisticRegr = LogisticRegression()\n",
    "    logisticRegr.fit(x_train, y_train)\n",
    "    classifiers.append(logisticRegr)\n",
    "    predicted = logisticRegr.predict(x_test)\n",
    "    accuracy,precision,recall,f1 =  core_utils.get_metrics(y_test, predicted)\n",
    "    output.append([format,learning,accuracy,precision,recall,f1])\n",
    "    \n",
    "    \n",
    "    learning = 'svm'\n",
    "    clf = svm.SVC(kernel='linear', C=1).fit(x_train, y_train)\n",
    "    classifiers.append(clf)\n",
    "    predicted = clf.predict(x_test)\n",
    "    accuracy,precision,recall,f1 =  core_utils.get_metrics(y_test, predicted)\n",
    "    output.append([format,learning,accuracy,precision,recall,f1])\n",
    "    \n",
    "    learning = 'xgboost'\n",
    "    xgbc = xgb.XGBClassifier()\n",
    "    xgbc.fit(x_train, y_train)\n",
    "    classifiers.append(xgbc)\n",
    "    predicted = xgbc.predict(x_test)\n",
    "    accuracy,precision,recall,f1 =  core_utils.get_metrics(y_test, predicted)\n",
    "    output.append([format,learning,accuracy,precision,recall,f1])\n",
    "    \n",
    "    learning = 'NN'\n",
    "    nn = MLPClassifier(solver='adam', alpha=1e-5,hidden_layer_sizes=(64), random_state=1,max_iter=500)\n",
    "    nn.fit(x_train,y_train)\n",
    "    classifiers.append(nn)\n",
    "    predicted = nn.predict(x_test)\n",
    "    accuracy,precision,recall,f1 =  core_utils.get_metrics(y_test, predicted)\n",
    "    output.append([format,learning,accuracy,precision,recall,f1])    \n",
    "\n",
    "df_results = pd.DataFrame(output,columns=header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this file already exists in the ouput folder\n",
    "# df_results.sort_values(by = ['learning','input']).to_csv('../outputs/class_all-mpnet-base-v2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table 2\n",
    "\n",
    " To reproduce Table 2 we need to run the cell __Experiment 1__ (above) but instead of using the default Sentence-BERT,\n",
    " the model has to be fine-tuned. The steps for this are:\n",
    " 1. Run the script fine_tune_script.py under work/experiments. \n",
    "     This script will store the fine-tuned model in /work/embedding/fine-tuned.\n",
    "     You could play with the params to get different results. Your results might be slightly different due to randomness.\n",
    "     <br>*Warning*: the process takes a long time and you might need a GPUs to finish in a reasonable time. We did not try with CPUs\n",
    " 2. Run the next two cell to run the classification with the fine-tuned model:\n",
    "     <br>-`sbert = SentenceTransformer('all-mpnet-base-v2')`\n",
    "     <br>+`sbert = SentenceTransformer('../embeddings/fine-tuned')`\n",
    " 3. To reproduce the results of the Semantic Search-based classifier, run the cell Table 2 complement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>learning</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>formatD</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.882022</td>\n",
       "      <td>0.870291</td>\n",
       "      <td>0.868756</td>\n",
       "      <td>0.869420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>formatD</td>\n",
       "      <td>svm</td>\n",
       "      <td>0.879213</td>\n",
       "      <td>0.866580</td>\n",
       "      <td>0.868200</td>\n",
       "      <td>0.867363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>formatD</td>\n",
       "      <td>xgboost</td>\n",
       "      <td>0.890449</td>\n",
       "      <td>0.878279</td>\n",
       "      <td>0.880049</td>\n",
       "      <td>0.879032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>formatD</td>\n",
       "      <td>NN</td>\n",
       "      <td>0.890449</td>\n",
       "      <td>0.879455</td>\n",
       "      <td>0.883182</td>\n",
       "      <td>0.881136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>formatD</td>\n",
       "      <td>s-search</td>\n",
       "      <td>0.821248</td>\n",
       "      <td>0.805128</td>\n",
       "      <td>0.797519</td>\n",
       "      <td>0.799724</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     input  learning  accuracy  precision    recall        f1\n",
       "0  formatD  logistic  0.882022   0.870291  0.868756  0.869420\n",
       "1  formatD       svm  0.879213   0.866580  0.868200  0.867363\n",
       "2  formatD   xgboost  0.890449   0.878279  0.880049  0.879032\n",
       "3  formatD        NN  0.890449   0.879455  0.883182  0.881136\n",
       "4  formatD  s-search  0.821248   0.805128  0.797519  0.799724"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If you rather not run the fine-tunning, you can read the results from here\n",
    "table_2 = pd.read_csv('../outputs/fine_tuned_formatD_results.csv')\n",
    "table_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## Table 2 full experiments with Semantic-Search classifier #\n",
    "\n",
    "df = pd.read_csv('../inputs/bert_3k_formatD.csv',index_col=None)\n",
    "df.drop_duplicates(keep='first',inplace=True)\n",
    "df['real'] = [true_labels[x] for x in df['keys']]\n",
    "\n",
    "X_original = df['docs'].values\n",
    "x_train, x_test, y_train, y_test = train_test_split(X_original,\n",
    "                                    df['real'].values, test_size=0.25, random_state=0) \n",
    "\n",
    "#reads the fine tunned model \n",
    "sbert = SentenceTransformer('../embeddings/fine-tuned')\n",
    "# alternative run the pre-trained model\n",
    "# sbert = SentenceTransformer('all-mpnet-base-v2')\n",
    "\n",
    "output = []\n",
    "format = 'format_D'\n",
    "# Run classifiers\n",
    "\n",
    "learning = 'logistic'\n",
    "logisticRegr = LogisticRegression()\n",
    "logisticRegr.fit(x_train, y_train)\n",
    "classifiers.append(logisticRegr)\n",
    "predicted = logisticRegr.predict(x_test)\n",
    "accuracy,precision,recall,f1 =  core_utils.get_metrics(y_test, predicted)\n",
    "output.append([format,learning,accuracy,precision,recall,f1])\n",
    "\n",
    "\n",
    "learning = 'svm'\n",
    "clf = svm.SVC(kernel='linear', C=1).fit(x_train, y_train)\n",
    "classifiers.append(clf)\n",
    "predicted = clf.predict(x_test)\n",
    "accuracy,precision,recall,f1 =  core_utils.get_metrics(y_test, predicted)\n",
    "output.append([format,learning,accuracy,precision,recall,f1])\n",
    "\n",
    "learning = 'xgboost'\n",
    "xgbc = xgb.XGBClassifier()\n",
    "xgbc.fit(x_train, y_train)\n",
    "classifiers.append(xgbc)\n",
    "predicted = xgbc.predict(x_test)\n",
    "accuracy,precision,recall,f1 =  core_utils.get_metrics(y_test, predicted)\n",
    "output.append([format,learning,accuracy,precision,recall,f1])\n",
    "\n",
    "learning = 'NN'\n",
    "nn = MLPClassifier(solver='adam', alpha=1e-5,hidden_layer_sizes=(64), random_state=1,max_iter=500)\n",
    "nn.fit(x_train,y_train)\n",
    "classifiers.append(nn)\n",
    "predicted = nn.predict(x_test)\n",
    "accuracy,precision,recall,f1 =  core_utils.get_metrics(y_test, predicted)\n",
    "output.append([format,learning,accuracy,precision,recall,f1])  \n",
    "\n",
    "corpus = x_train.copy()\n",
    "corpus_embeddings = sbert.encode(corpus, convert_to_tensor=True)\n",
    "predicted = []\n",
    "queries = x_test.copy()\n",
    "learning = 'sem-search'\n",
    "for query in queries:\n",
    "    query_embedding = sbert.encode(query, convert_to_tensor=True)\n",
    "    hits = util.semantic_search(query_embedding, corpus_embeddings, top_k=1)\n",
    "    id_corpus = hits[0][0]['corpus_id']\n",
    "    label_to_compare = y_train[id_corpus]\n",
    "    predicted.append(label_to_compare)\n",
    "accuracy,precision,recall,f1 =  core_utils.get_metrics(y_test, predicted)\n",
    "output.append([format,learning,accuracy,precision,recall,f1])  \n",
    "df_results = pd.DataFrame(output,columns=header)\n",
    "df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline comparison\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# At this point, you should have the results of docflow using the pre-trained and fine-tuned model\n",
    "# Alternative you can re-run this cell using the Format_D\n",
    "\n",
    "df = pd.read_csv('../inputs/bert_3k_formatD.csv',index_col=None)\n",
    "df.drop_duplicates(keep='first',inplace=True)\n",
    "df['real'] = [true_labels[x] for x in df['keys']]\n",
    "\n",
    "\n",
    "sbert = SentenceTransformer('all-mpnet-base-v2')\n",
    "\n",
    "X_original = sbert.encode(df['docs'].values)\n",
    "x_train, x_test, y_train, y_test = train_test_split(X_original,\n",
    "                                 label_encoded_y, test_size=0.25, random_state=0) \n",
    "output = []\n",
    "embedding = 'pretrained'\n",
    "learning = 'xgboost'\n",
    "model = xgb.XGBClassifier()\n",
    "model.fit(x_train, y_train)\n",
    "predicted = model.predict(x_test)\n",
    "accuracy,precision,recall,f1 =  core_utils.get_metrics(y_test, predicted)\n",
    "output.append([embedding,learning,accuracy,precision,recall,f1])  \n",
    "\n",
    "embedding = 'fine_tuned'\n",
    "learning = 'xgboost'\n",
    "sbert2 = SentenceTransformer('../embeddings/fine_tunned')\n",
    "X_original = sbert2.encode(df['docs'].values)\n",
    "x_train, x_test, y_train, y_test = train_test_split(X_original,\n",
    "                                 label_encoded_y, test_size=0.25, random_state=0) #\n",
    "                                 \n",
    "model = xgb.XGBClassifier()\n",
    "model.fit(x_train, y_train)\n",
    "predicted = model.predict(x_test)\n",
    "accuracy,precision,recall,f1 =  core_utils.get_metrics(y_test, predicted)\n",
    "output.append([embedding,learning,accuracy,precision,recall,f1]) \n",
    "df_results = pd.DataFrame(output,columns=header)\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7614165890027959, 0.7954411100625199, 0.772415376177863, 0.7700876517552854)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We show the results from SuSi experiments\n",
    "core_utils.get_metrics(df_labels['real'],df_labels['classification'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8941281138790036,\n",
       " 0.6766939394341231,\n",
       " 0.7603571302648873,\n",
       " 0.6563579747624534)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We read the SWAM labels and show the metrics\n",
    "swam = pd.read_csv('../inputs/swam_labels.csv')\n",
    "core_utils.get_metrics(swam['sw_class'],swam['true_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# swam.drop(columns=['keys','real']).to_csv('../inputs/swam_labels.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Semantic categories experiments\n",
    "\n",
    "This part shows the result for the Semantic Category experiments. In case you want to run the full experiment, see the below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tool</th>\n",
       "      <th>format</th>\n",
       "      <th>accu</th>\n",
       "      <th>m_prec</th>\n",
       "      <th>m_rec</th>\n",
       "      <th>w_prec</th>\n",
       "      <th>w_rec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>docflow</td>\n",
       "      <td>format_E</td>\n",
       "      <td>0.863128</td>\n",
       "      <td>0.784420</td>\n",
       "      <td>0.827205</td>\n",
       "      <td>0.914059</td>\n",
       "      <td>0.863128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>docflow</td>\n",
       "      <td>format_F</td>\n",
       "      <td>0.837989</td>\n",
       "      <td>0.824618</td>\n",
       "      <td>0.828340</td>\n",
       "      <td>0.899385</td>\n",
       "      <td>0.837989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>docflow</td>\n",
       "      <td>format_G</td>\n",
       "      <td>0.790503</td>\n",
       "      <td>0.787120</td>\n",
       "      <td>0.761325</td>\n",
       "      <td>0.898293</td>\n",
       "      <td>0.790503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>susi</td>\n",
       "      <td>format_E</td>\n",
       "      <td>0.597765</td>\n",
       "      <td>0.711640</td>\n",
       "      <td>0.596003</td>\n",
       "      <td>0.885422</td>\n",
       "      <td>0.597765</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      tool    format      accu    m_prec     m_rec    w_prec     w_rec\n",
       "1  docflow  format_E  0.863128  0.784420  0.827205  0.914059  0.863128\n",
       "3  docflow  format_F  0.837989  0.824618  0.828340  0.899385  0.837989\n",
       "5  docflow  format_G  0.790503  0.787120  0.761325  0.898293  0.790503\n",
       "0     susi  format_E  0.597765  0.711640  0.596003  0.885422  0.597765"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Table 4 results\n",
    "datasets = ['zero_format_E.csv','zero_format_F.csv','zero_format_G.csv']\n",
    "results = []\n",
    "result_total = []\n",
    "for in_format in datasets:\n",
    "    out = pd.read_csv(f'../outputs/{in_format}')\n",
    "    in_name = in_format.replace('.csv','').replace('zero_','')\n",
    "    out['category_map_final'] = core_utils.add_cat_map(out,core_utils.inverse_map_susi)\n",
    "    cols = ['category_map_final','pred_final']\n",
    "    for col in cols:\n",
    "        tool_name = 'docflow' if col == 'pred_final' else 'susi'\n",
    "        metrics_cv = metrics.classification_report(out['real_final'], out[col],output_dict=True,zero_division=0)\n",
    "        #results by averaging\n",
    "        accu = metrics_cv['accuracy']\n",
    "        macro_avg = metrics_cv['macro avg']\n",
    "        weighted_avg = metrics_cv['weighted avg']\n",
    "        result_total.append([tool_name,in_name,accu,macro_avg['precision'],macro_avg['recall'],weighted_avg['precision'],weighted_avg['recall']])\n",
    "        # results per category\n",
    "        for category in out[col].unique():\n",
    "            res = metrics_cv[category]\n",
    "            results.append([tool_name,in_name,category,res['precision'],res['recall'],res['f1-score']])\n",
    "df_result_cat = pd.DataFrame(results,columns=['tool','format','category','precision','recall','f1'])\n",
    "df_result_total = pd.DataFrame(result_total,columns=['tool','format','accu','m_prec','m_rec','w_prec','w_rec'])\n",
    "df_result_total = df_result_total.drop(df_result_total[(df_result_total['tool'] == 'susi') & (df_result_total['format'] != 'format_E')].index)\n",
    "df_result_total.sort_values(by=['tool','format'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############## Table 4 Experiments (~2h running time)  ############## \n",
    "\n",
    "\n",
    "from transformers import pipeline\n",
    "classifier = pipeline(\"zero-shot-classification\",\n",
    "                      model=\"facebook/bart-large-mnli\")\n",
    "labels = pd.read_csv('../inputs/zeroshot_input_susi_true_label_final.csv')\n",
    "real_cat_map = {x:y for x,y in list(zip(labels['key'],labels['real_cat']))}\n",
    "\n",
    "base = '../inputs/'\n",
    "datasets = ['zeroshot_input_susi_format_E.csv','zeroshot_input_susi_format_F.csv','zeroshot_input_susi_format_G.csv']\n",
    "tmp_labels = ['log', 'nfc communication', 'audio', 'user account', 'user information','text message',\n",
    "       'file information', 'network connection', 'geolocation', 'bluetooth','system settings','calendar information',\n",
    "       'text message', 'contact information','media','network information','database','database information']\n",
    "\n",
    "for dataset in datasets:\n",
    "    format_name = dataset.split('_')[-1].replace('.csv','')\n",
    "    df = pd.read_csv(base + dataset)\n",
    "    df = df.loc[df['key'].isin(labels['key'])]\n",
    "    df['real_cat'] = [real_cat_map[x] for x in df['key']]\n",
    "    df = df.head(10)\n",
    "    output = []\n",
    "    for text in df['docs']:\n",
    "        out = classifier(text, tmp_labels)\n",
    "        output.append([out['labels'][0],out['scores'][0]])\n",
    "    df['label'] = [x[0] for x in output]\n",
    "    df['scores'] = [x[1] for x in output]\n",
    "    df['real_final'] = [core_utils.inverse_map_real[x] for x in df['real_cat']]\n",
    "    df['pred_final'] = [core_utils.inverse_map_pred[x] for x in df['label']]\n",
    "    df.to_csv(f'../output/zero_format_{format_name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Platform libraries experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Library</th>\n",
       "      <th>Package</th>\n",
       "      <th>Srcs</th>\n",
       "      <th>Sinks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wearable</td>\n",
       "      <td>com.google.android.gms.wearable</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TV</td>\n",
       "      <td>com.google.android.gms.cast.tv</td>\n",
       "      <td>0.92</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Analytics</td>\n",
       "      <td>com.google.android.gms.analytics</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ads</td>\n",
       "      <td>com.google.android.gms.ads</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Library                           Package  Srcs  Sinks\n",
       "0   Wearable   com.google.android.gms.wearable  0.95   0.96\n",
       "1         TV    com.google.android.gms.cast.tv  0.92   1.00\n",
       "2  Analytics  com.google.android.gms.analytics  1.00   0.93\n",
       "3        Ads        com.google.android.gms.ads  0.92   0.85"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " # Table 5 Results\n",
    "\n",
    "table_5 = pd.read_csv('../outputs/libraries_prediction_detection.csv')\n",
    "table_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table 5 Experiments. \n",
    "# The approach here is to train the classifiers and then use the ones with best performance\n",
    "# to predict the labels for Google Play Services methods. \n",
    "\n",
    "inputs = ['bert_3k_formatC.csv','bert_3k_formatD.csv']\n",
    "base = '../inputs/'\n",
    "header = ['input','learning','accuracy','precision','recall','f1']\n",
    "df_labels = pd.read_csv(f'{base}bert_3k_true_labels.csv',index_col=None)\n",
    "df_labels.drop_duplicates(subset=['keys'],keep='first',inplace=True)\n",
    "true_labels = dict(zip(df_labels['keys'],df_labels['real']))\n",
    "# store the models for latter predictions\n",
    "classifiers = []\n",
    "output = []\n",
    "\n",
    "for input in inputs:\n",
    "    df = pd.read_csv(base + input,index_col=None)\n",
    "    df.drop_duplicates(keep='first',inplace=True)\n",
    "    df['real'] = [true_labels[x] for x in df['keys']]\n",
    "\n",
    "    # use the fine tunned model if available. 'all-mpnet-base-v2' still produce similar results\n",
    "    # sbert = SentenceTransformer('../embeddings/fine_tunned') \n",
    "    sbert = SentenceTransformer('all-mpnet-base-v2')\n",
    "    \n",
    "    X_original = sbert.encode(df['docs'].values)\n",
    "    embedding = input.replace('.csv','').replace('bert_3k_','')\n",
    "\n",
    "\n",
    "    label_encoder = LabelEncoder()\n",
    "    label_encoder = label_encoder.fit(df['real'].values)\n",
    "    label_encoded_y = label_encoder.transform(df['real'].values)\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X_original,\n",
    "                                         label_encoded_y, test_size=0.15, random_state=0) \n",
    "\n",
    "\n",
    "    learning = 'xgboost'\n",
    "    model = xgb.XGBClassifier()\n",
    "    model.fit(x_train, y_train)\n",
    "    classifiers.append(model)\n",
    "    predicted = model.predict(x_test)\n",
    "    accuracy,precision,recall,f1 =  core_utils.get_metrics(y_test, predicted)\n",
    "    output.append([embedding,learning,accuracy,precision,recall,f1])\n",
    "    \n",
    "    learning = 'NN'\n",
    "    nn = MLPClassifier(solver='adam', alpha=1e-5,hidden_layer_sizes=(64), random_state=1,max_iter=500)\n",
    "    nn.fit(x_train,y_train)\n",
    "    classifiers.append(nn)\n",
    "    predicted = nn.predict(x_test)\n",
    "    accuracy,precision,recall,f1 =  core_utils.get_metrics(y_test, predicted)\n",
    "    output.append([embedding,learning,accuracy,precision,recall,f1])\n",
    "\n",
    "# df_results = pd.DataFrame(output,columns=header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(513, 4)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is the dataset of Google libraries with the ground truth\n",
    "df_input = pd.read_csv('../inputs/test_experiment_libs_nodup_D.csv',index_col=False)\n",
    "df_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((513, 768), (513,))"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We first need to embed the documentation from the test set\n",
    "test_emb = sbert.encode(df_input['docs'].values)\n",
    "label_encoded_test_y = label_encoder.transform(df_input['classification'].values)\n",
    "test_emb.shape,label_encoded_test_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, we make the predictions for the test set\n",
    "predictions = []\n",
    "output2 = []\n",
    "for clf,learning,embedding in [(classifiers[2],'xg','d'),(classifiers[3],'nn','d'),(classifiers[0],'xg','c')]:\n",
    "    predicted = clf.predict(test_emb)\n",
    "    predictions.append(predicted)\n",
    "    accuracy,precision,recall,f1 =  core_utils.get_metrics(label_encoded_test_y, predicted)\n",
    "    output2.append([embedding,learning,accuracy,precision,recall,f1])\n",
    "df_results2 = pd.DataFrame(output2,columns=header)\n",
    "df_input['xg_d'] = label_encoder.inverse_transform(predictions[0])\n",
    "df_input['nn_d'] = label_encoder.inverse_transform(predictions[1])\n",
    "df_input['xg_c'] = label_encoder.inverse_transform(predictions[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wear Library: Total/detected\n",
      "Sources\n",
      "32 28\n",
      "Sinks\n",
      "(89, 7) (85, 7)\n",
      "TV Library: Total/detected\n",
      "Sources\n",
      "(3, 7) (3, 7)\n",
      "Sinks\n",
      "(14, 7) (14, 7)\n",
      "Analytics Library: Total/detected\n",
      "Sources\n",
      "(29, 7) (25, 7)\n",
      "Sinks\n",
      "(9, 7) (9, 7)\n",
      "Ads Library: Total/detected\n",
      "Sources\n",
      "(14, 7) (12, 7)\n",
      "Sinks\n",
      "(63, 7) (57, 7)\n"
     ]
    }
   ],
   "source": [
    "totals = []\n",
    "print('Wear Library: Total/detected')\n",
    "print('Sources')\n",
    "lib_wear = df_input.loc[df_input.library == 'wearable']\n",
    "print(lib_wear.loc[(lib_wear.classification == 'sink')].shape[0], \\\n",
    "lib_wear.loc[(lib_wear.classification == 'sink') & (lib_wear.classification == lib_wear.xg_d) ].shape[0])\n",
    "print('Sinks')\n",
    "print(lib_wear.loc[(lib_wear.classification == 'source')].shape[0], \\\n",
    "lib_wear.loc[(lib_wear.classification == 'source') & (lib_wear.classification == lib_wear.xg_d) ].shape[0])\n",
    "print('TV Library: Total/detected')\n",
    "print('Sources')\n",
    "lib_tv = df_input.loc[df_input.library == 'tv']\n",
    "print(lib_tv.loc[(lib_tv.classification == 'sink')].shape[0], \\\n",
    "lib_tv.loc[(lib_tv.classification == 'sink') & (lib_tv.classification == lib_tv.xg_d) ].shape[0])\n",
    "print('Sinks')\n",
    "print(lib_tv.loc[(lib_tv.classification == 'source')].shape[0], \\\n",
    "lib_tv.loc[(lib_tv.classification == 'source') & (lib_tv.classification == lib_tv.xg_d) ].shape[0])\n",
    "print('Analytics Library: Total/detected')\n",
    "print('Sources')\n",
    "analytic = df_input.loc[df_input.library.isin(['analytics'])]\n",
    "print(analytic.loc[(analytic.classification == 'sink')].shape[0], \\\n",
    "analytic.loc[(analytic.classification == 'sink') & (analytic.classification == analytic.xg_d) ].shape[0])\n",
    "print('Sinks')\n",
    "print(analytic.loc[(analytic.classification == 'source')].shape[0], \\\n",
    "analytic.loc[(analytic.classification == 'source') & (analytic.classification == analytic.xg_d) ].shape[0])\n",
    "print('Ads Library: Total/detected')\n",
    "print('Sources')\n",
    "ads = df_input.loc[df_input.library.isin(['ads'])]\n",
    "print(ads.loc[(ads.classification == 'sink')].shape[0], \\\n",
    "ads.loc[(ads.classification == 'sink') & (ads.classification == ads.xg_d) ].shape[0])\n",
    "print('Sinks')\n",
    "print(ads.loc[(ads.classification == 'source')].shape[0], \\\n",
    "ads.loc[(ads.classification == 'source') & (ads.classification == ads.xg_d) ].shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Taint specification generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lib</th>\n",
       "      <th>name</th>\n",
       "      <th>fqname</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cac</td>\n",
       "      <td>UserAction</td>\n",
       "      <td>com.google.android.gms.cast.tv.cac.UserAction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cac</td>\n",
       "      <td>UserActionContext</td>\n",
       "      <td>com.google.android.gms.cast.tv.cac.UserActionC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>measurement</td>\n",
       "      <td>AppMeasurementContentProvider</td>\n",
       "      <td>com.google.android.gms.measurement.AppMeasurem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>measurement</td>\n",
       "      <td>AppMeasurementJobService</td>\n",
       "      <td>com.google.android.gms.measurement.AppMeasurem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>measurement</td>\n",
       "      <td>AppMeasurementReceiver</td>\n",
       "      <td>com.google.android.gms.measurement.AppMeasurem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1760</th>\n",
       "      <td>wearable</td>\n",
       "      <td>MessageApi.MessageListener</td>\n",
       "      <td>com.google.android.gms.wearable.MessageApi.Mes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1761</th>\n",
       "      <td>wearable</td>\n",
       "      <td>MessageApi.SendMessageResult</td>\n",
       "      <td>com.google.android.gms.wearable.MessageApi.Sen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1762</th>\n",
       "      <td>wearable</td>\n",
       "      <td>NodeApi.GetConnectedNodesResult</td>\n",
       "      <td>com.google.android.gms.wearable.NodeApi.GetCon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1763</th>\n",
       "      <td>wearable</td>\n",
       "      <td>NodeApi.GetLocalNodeResult</td>\n",
       "      <td>com.google.android.gms.wearable.NodeApi.GetLoc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1764</th>\n",
       "      <td>wearable</td>\n",
       "      <td>Wearable.WearableOptions.Builder</td>\n",
       "      <td>com.google.android.gms.wearable.Wearable.Weara...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1765 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              lib                              name  \\\n",
       "0             cac                        UserAction   \n",
       "1             cac                 UserActionContext   \n",
       "2     measurement     AppMeasurementContentProvider   \n",
       "3     measurement          AppMeasurementJobService   \n",
       "4     measurement            AppMeasurementReceiver   \n",
       "...           ...                               ...   \n",
       "1760     wearable        MessageApi.MessageListener   \n",
       "1761     wearable      MessageApi.SendMessageResult   \n",
       "1762     wearable   NodeApi.GetConnectedNodesResult   \n",
       "1763     wearable        NodeApi.GetLocalNodeResult   \n",
       "1764     wearable  Wearable.WearableOptions.Builder   \n",
       "\n",
       "                                                 fqname  \n",
       "0         com.google.android.gms.cast.tv.cac.UserAction  \n",
       "1     com.google.android.gms.cast.tv.cac.UserActionC...  \n",
       "2     com.google.android.gms.measurement.AppMeasurem...  \n",
       "3     com.google.android.gms.measurement.AppMeasurem...  \n",
       "4     com.google.android.gms.measurement.AppMeasurem...  \n",
       "...                                                 ...  \n",
       "1760  com.google.android.gms.wearable.MessageApi.Mes...  \n",
       "1761  com.google.android.gms.wearable.MessageApi.Sen...  \n",
       "1762  com.google.android.gms.wearable.NodeApi.GetCon...  \n",
       "1763  com.google.android.gms.wearable.NodeApi.GetLoc...  \n",
       "1764  com.google.android.gms.wearable.Wearable.Weara...  \n",
       "\n",
       "[1765 rows x 3 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gps_class_df = pd.read_csv('../inputs/gps_classes_qname.csv')\n",
    "gps_class_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(core_utils) \n",
    "\n",
    "df = pd.read_csv('../inputs/gps_data_predictions_format_D.csv')\n",
    "gps = pd.read_csv('../inputs/gps_data.csv')\n",
    "gps_map = {k:v for k,v in list(zip(gps['key'],gps['library']))}\n",
    "df['library'] = [gps_map[x] for x in df['key']]\n",
    "merge = gps.merge(df[['key','nn']],how='left',on=['key']).drop_duplicates(subset=['key','args_string'])\n",
    "merge = merge.loc[merge['nn'].isin(['source','sink'])]\n",
    "\n",
    "gps_class_df = pd.read_csv('../inputs/gps_classes_qname.csv')\n",
    "aosp_class_map = core_utils.get_aosp_map()\n",
    "\n",
    "# generate specifications for TV libraries. This example considers TV sources/sinks\n",
    "targets = ['cast','tv']\n",
    "method_sources = merge.loc[(merge['library'].isin(targets)) & (merge['nn'] == 'source')]\n",
    "method_sources.shape\n",
    "\n",
    "#Format: <class: return_type method_name(param1,...)> -> _SOURCE_\n",
    "stmts = []\n",
    "for _,row in method_sources.iterrows():\n",
    "    args = eval(row['args'])\n",
    "    if args[0] == '':\n",
    "        args_fill = ''\n",
    "    else:\n",
    "        args = [core_utils.get_qualify_name(x,row['library'],aosp_class_map,gps_class_df) for x in args]\n",
    "        args_fill = ','.join(args)\n",
    "    qclass = core_utils.get_qualify_name(row['class'],row['library'],aosp_class_map,gps_class_df)\n",
    "    qreturn = core_utils.get_qualify_name(row['return'],row['library'],aosp_class_map,gps_class_df)\n",
    "    tmp = ['<',qclass,': ',qreturn,' ',row['method_name'],f\"({args_fill})> -> \",f\"_{row['nn'].upper()}_\"]\n",
    "    stmts.append(tmp)\n",
    "with open('../outputs/sources_specifications.txt','w') as f:\n",
    "    for stmt in stmts:\n",
    "        f.write(''.join(stmt) + '\\n')\n",
    "\n",
    "\n",
    "method_sinks = merge.loc[(merge['library'].isin(targets)) & (merge['nn'] == 'sink')]\n",
    "method_sinks.shape\n",
    "\n",
    "#Format: <class: return_type method_name(param1,...)> -> _SINK_\n",
    "stmts = []\n",
    "for _,row in method_sinks.iterrows():\n",
    "    args = eval(row['args'])\n",
    "    if args[0] == '':\n",
    "        args_fill = ''\n",
    "    else:\n",
    "        args = [core_utils.get_qualify_name(x,row['library'],aosp_class_map,gps_class_df) for x in args]\n",
    "        args_fill = ','.join(args)\n",
    "    qclass = core_utils.get_qualify_name(row['class'],row['library'],aosp_class_map,gps_class_df)\n",
    "    qreturn = core_utils.get_qualify_name(row['return'],row['library'],aosp_class_map,gps_class_df)\n",
    "    tmp = ['<',qclass,': ',qreturn,' ',row['method_name'],f\"({args_fill})> -> \",f\"_{row['nn'].upper()}_\"]\n",
    "    stmts.append(tmp)\n",
    "with open('../outputs/sinks_specification.txt','w') as f:\n",
    "    for stmt in stmts:\n",
    "        f.write(''.join(stmt) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Robustness Software evolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_97/1644472967.py:3: MatplotlibDeprecationWarning: The seaborn styles shipped by Matplotlib are deprecated since 3.6, as they no longer correspond to the styles shipped by seaborn. However, they will remain available as 'seaborn-v0_8-<style>'. Alternatively, directly use the seaborn API instead.\n",
      "  plt.style.use('seaborn')\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "plt.style.use('seaborn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>version</th>\n",
       "      <th>total</th>\n",
       "      <th>methods</th>\n",
       "      <th>sources</th>\n",
       "      <th>sinks</th>\n",
       "      <th>missed_sources</th>\n",
       "      <th>missed_sinks</th>\n",
       "      <th>API level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018</td>\n",
       "      <td>151</td>\n",
       "      <td>110</td>\n",
       "      <td>53</td>\n",
       "      <td>24</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020</td>\n",
       "      <td>165</td>\n",
       "      <td>117</td>\n",
       "      <td>56</td>\n",
       "      <td>25</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021</td>\n",
       "      <td>186</td>\n",
       "      <td>137</td>\n",
       "      <td>64</td>\n",
       "      <td>30</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022</td>\n",
       "      <td>195</td>\n",
       "      <td>148</td>\n",
       "      <td>68</td>\n",
       "      <td>30</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  version  total  methods  sources  sinks  missed_sources  missed_sinks  \\\n",
       "0    2018    151      110       53     24              11             1   \n",
       "1    2020    165      117       56     25              11             1   \n",
       "2    2021    186      137       64     30               8             1   \n",
       "3    2022    195      148       68     30               8             1   \n",
       "\n",
       "  API level  \n",
       "0        29  \n",
       "1        30  \n",
       "2        31  \n",
       "3        32  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read results from the classification of the methods of the Location package (4 versions)\n",
    "\n",
    "df_input = pd.read_csv('../inputs/location_pkgs_with_predictions.csv',index_col=None)\n",
    "df_input = df_input.astype({'version':str})\n",
    "\n",
    "android_map = {'2018':'29','2020':'30','2021':'31','2022':'32'}\n",
    "analysis = []\n",
    "for vers in df_input.version.unique():\n",
    "    total = df_input.loc[(df_input.version == vers)].shape[0]\n",
    "    tmp = df_input.loc[(df_input.version == vers) & (df_input.classification == df_input.xg_d)]\n",
    "    tmp_false = df_input.loc[(df_input.version == vers) & (df_input.classification != df_input.xg_d)]\n",
    "    so = tmp.loc[tmp.classification == 'source']\n",
    "    so_false = tmp_false.loc[tmp_false.classification == 'source']\n",
    "    si = tmp.loc[tmp.classification == 'sink']\n",
    "    si_false = tmp_false.loc[tmp_false.classification == 'sink']\n",
    "    analysis.append((vers,total,tmp.shape[0],so.shape[0],si.shape[0],so_false.shape[0],si_false.shape[0]))\n",
    "df_analysis = pd.DataFrame(analysis,columns=['version','total','methods','sources','sinks','missed_sources','missed_sinks'])\n",
    "df_analysis['API level'] = [android_map[x] for x in df_analysis['version'] ]\n",
    "df_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 4\n",
    "sources = (53, 56, 64, 68)\n",
    "sources_missed =   (11,11,8,8)\n",
    "\n",
    "ind = np.arange(N)  # the x locations for the groups\n",
    "width = 0.35       # the width of the bars\n",
    "\n",
    "fig = plt.figure(figsize=(10, 6))\n",
    "ax = fig.add_subplot(111)\n",
    "rects1 = ax.bar(ind, sources, width, yerr=sources_missed) #color='royalblue'\n",
    "\n",
    "sinks = (24,25,30,30)\n",
    "sinks_missed =   (1,1,1,1)\n",
    "rects2 = ax.bar(ind+width, sinks, width, yerr=sinks_missed) # , color='seagreen'\n",
    "\n",
    "# add some formatting\n",
    "ax.set_ylabel('Total Method', fontsize=15)\n",
    "ax.set_xlabel('API level', fontsize=15)\n",
    "ax.set_xticks(ind + width / 2)\n",
    "ax.set_xticklabels( (29,30,31,32),fontsize=14 )\n",
    "ax.legend( (rects1[0], rects2[0]), ('Sources', 'Sinks'),fontsize=14 )\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the fine-tuned model to get similar results as the paper\n",
    "# The pre-trained model might not display the clusters as good as the fine-tuned model but still works\n",
    "sbert = SentenceTransformer('../embeddings/fine_tunned')\n",
    "# sbert = SentenceTransformer('all-mpnet-base-v2')\n",
    "\n",
    "df_sosi = df_input.loc[df_input.classification.isin(['source','sink'])].copy()\n",
    "class_map = {'source':0,'sink':1,'neither':0}\n",
    "df_sosi['label'] = [class_map[x] for x in df_sosi['classification']]\n",
    "corpus_sosi = df_sosi['docs'].values\n",
    "sosi_embeddings = sbert.encode(corpus_sosi, batch_size=64, show_progress_bar=False, convert_to_tensor=True)\n",
    "tsne = TSNE(n_components=2, random_state=0)\n",
    "vectors = tsne.fit_transform(sosi_embeddings)\n",
    "df_sosi['x_vals'] = [v[0] for v in vectors]\n",
    "df_sosi['y_vals'] = [v[1] for v in vectors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_vers = {'2018':'29','2020':'30','2021':'31','2022':'32'}\n",
    "cluster_plot_full = df_sosi.loc[(df_sosi['version'].isin(['2021','2022'])) & (df_sosi['classification'].isin(['source','sink']))].copy()\n",
    "cluster_plot_full['API level'] = [map_vers[x] for x in cluster_plot_full['version'].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize':(15,11)})\n",
    "markers =  {\"31\": \"o\", \"32\": \"X\"}\n",
    "\n",
    "ax = sns.scatterplot(data=cluster_plot_full, x='x_vals', y='y_vals',\n",
    "    hue='classification', style='API level',legend='brief',s=120,markers=markers)\n",
    "ax.set(xlabel=None,ylabel=None)\n",
    "\n",
    "# ax.tick_params(bottom=False)\n",
    "sns.move_legend(ax, \"upper left\") #,bbox_to_anchor=(1, -0.1)\n",
    "plt.setp(ax.get_legend().get_texts(), fontsize='14') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_plot_full = df_sosi.loc[(df_sosi['version'].isin(['2018','2020'])) & (df_sosi['classification'].isin(['source','sink']))].copy()\n",
    "cluster_plot_full['API level'] = [map_vers[x] for x in cluster_plot_full['version'].values]\n",
    "sns.set(rc={'figure.figsize':(10,7)})\n",
    "markers =  {\"29\": \"o\", \"30\": \"X\"}\n",
    "\n",
    "ax = sns.scatterplot(data=cluster_plot_full, x='x_vals', y='y_vals',\n",
    "    hue='classification', style='API level',legend='brief',s=90,markers=markers)\n",
    "ax.set(xlabel=None,ylabel=None)\n",
    "\n",
    "# ax.tick_params(bottom=False)\n",
    "sns.move_legend(ax, \"upper left\") #,bbox_to_anchor=(1, -0.1)\n",
    "plt.setp(ax.get_legend().get_texts(), fontsize='12') \n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
